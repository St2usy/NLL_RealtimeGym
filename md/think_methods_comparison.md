# ì„¸ ê°€ì§€ ì—ì´ì „íŠ¸ì˜ `think()` ë©”ì„œë“œ ë¹„êµ ë¶„ì„

## ğŸ“Š ì „ì²´ ë¹„êµí‘œ

| íŠ¹ì§• | ReactiveAgent | PlanningAgent | AgileThinker |
|------|--------------|---------------|--------------|
| **ì‚¬ìš© ëª¨ë¸** | model1 (reactive) | model2 (planning) | model1 + model2 (hybrid) |
| **ì¶”ë¡  ë°©ì‹** | ì¦‰ì‹œ ë°˜ì‘ | ì¥ê¸° ê³„íš | ê³„íš + ë°˜ì‘ ê²°í•© |
| **ì½”ë“œ ë¼ì¸** | 19ì¤„ (ê°„ë‹¨) | 35ì¤„ (ì¤‘ê°„) | 37ì¤„ (ë³µì¡) |
| **í”„ë¡¬í”„íŠ¸ ëª¨ë“œ** | `"reactive"` | `"planning"` | `"agile"` (dict) |
| **ì˜ˆì‚° ì‚¬ìš©** | ì „ì²´ë¥¼ reactiveì— ì‚¬ìš© | ì „ì²´ë¥¼ planningì— ì‚¬ìš© | planning + reactive ë¶„í•  |
| **ê³„íš ìƒì„±** | âŒ ì—†ìŒ | âœ… `\boxed{}` ì•¡ì…˜ ì‹œí€€ìŠ¤ | âœ… í…ìŠ¤íŠ¸ ê°€ì´ë˜ìŠ¤ |
| **ê³„íš ì¬ì‚¬ìš©** | âŒ | âœ… ì—¬ëŸ¬ í„´ì— ê±¸ì³ ì‚¬ìš© | âœ… reactiveì— ì „ë‹¬ |

---

## 1ï¸âƒ£ ReactiveAgent.think() - ì¦‰ì‹œ ë°˜ì‘ ì „ëµ

**ìœ„ì¹˜**: `src/realtimegym/agents/reactive.py:22-40`

```python
def think(self, timeout: Optional[float] = None) -> None:
    assert self.current_observation is not None and timeout is not None
    budget = timeout
    observation = self.current_observation
    prompt_gen = self.prompts.state_to_description(
        observation["state"], mode="reactive"
    )
    messages = [{"role": "user", "content": prompt_gen}]
    text, token_num = self.reactive_inference(messages, budget)
    self.action = re.sub(
        r"[^" + self.prompts.ALL_ACTIONS + "]", "", extract_boxed(text)
    )
    if self.action == "":
        self.action = self.prompts.DEFAULT_ACTION
    if self.log_thinking:
        self.logs["plan"].append("N/A")
        self.logs["model1_prompt"].append(messages[-1]["content"])
        self.logs["model1_response"].append(text)
    self.logs["model1_token_num"].append(token_num)
```

### í•µì‹¬ íŠ¹ì§•

**ğŸ¯ ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ ì˜ì‚¬ê²°ì •**
- í˜„ì¬ ê´€ì°°ë§Œ ë³´ê³  ì¦‰ì‹œ ì•¡ì…˜ ê²°ì •
- ì¥ê¸° ê³„íš ì—†ì´ ë°˜ì‚¬ì ìœ¼ë¡œ ëŒ€ì‘
- ê°€ì¥ ì§§ê³  ë‹¨ìˆœí•œ ì½”ë“œ

### ë‹¨ê³„ë³„ ë¶„ì„

#### Step 1: ì…ë ¥ ê²€ì¦ (Line 23)
```python
assert self.current_observation is not None and timeout is not None
```
**Python ë¬¸ë²•: `assert` ë¬¸**
- ì¡°ê±´ì´ `False`ë©´ `AssertionError` ë°œìƒ
- ë””ë²„ê¹…ìš©, í”„ë¡œë•ì…˜ì—ì„œëŠ” ë¹„í™œì„±í™” ê°€ëŠ¥
- **ë…¼ë¦¬ ì—°ì‚°ì `and`**: ë‘ ì¡°ê±´ ëª¨ë‘ `True`ì—¬ì•¼ í†µê³¼

#### Step 2: í”„ë¡¬í”„íŠ¸ ìƒì„± (Line 26-28)
```python
prompt_gen = self.prompts.state_to_description(
    observation["state"], mode="reactive"
)
messages = [{"role": "user", "content": prompt_gen}]
```
**Python ë¬¸ë²•: ë¦¬ìŠ¤íŠ¸ì™€ ë”•ì…”ë„ˆë¦¬**
- `[...]`: ë¦¬ìŠ¤íŠ¸ ë¦¬í„°ëŸ´ (ìˆœì„œ ìˆëŠ” ì»¬ë ‰ì…˜)
- `{...}`: ë”•ì…”ë„ˆë¦¬ ë¦¬í„°ëŸ´ (í‚¤-ê°’ ìŒ)
- OpenAI API í˜•ì‹: `[{"role": "user", "content": "..."}]`

#### Step 3: ì¶”ë¡  ì‹¤í–‰ (Line 30)
```python
text, token_num = self.reactive_inference(messages, budget)
```
**Python ë¬¸ë²•: íŠœí”Œ ì–¸íŒ¨í‚¹ (Tuple Unpacking)**
- í•¨ìˆ˜ê°€ ì—¬ëŸ¬ ê°’ì„ ë°˜í™˜í•  ë•Œ ì‚¬ìš©
- `reactive_inference()`ëŠ” `(text, token_num)` íŠœí”Œ ë°˜í™˜
- ì¢Œë³€ì˜ ë³€ìˆ˜ì— ìˆœì„œëŒ€ë¡œ í• ë‹¹

#### Step 4: ì•¡ì…˜ ì¶”ì¶œ (Line 31-35)
```python
self.action = re.sub(
    r"[^" + self.prompts.ALL_ACTIONS + "]", "", extract_boxed(text)
)
if self.action == "":
    self.action = self.prompts.DEFAULT_ACTION
```
**ì •ê·œí‘œí˜„ì‹ (Regex)**
- `re.sub(pattern, replacement, string)`: íŒ¨í„´ ë§¤ì¹­ë˜ëŠ” ë¶€ë¶„ì„ replacementë¡œ ì¹˜í™˜
- `r"[^...]"`: raw string (ì—­ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í”„ ë¶ˆí•„ìš”)
- `[^ABC]`: ë¬¸ì í´ë˜ìŠ¤ ë¶€ì • (A, B, Cê°€ ì•„ë‹Œ ëª¨ë“  ë¬¸ì)
- ì˜ˆ: `ALL_ACTIONS="UDLR"`ì´ë©´ `[^UDLR]`ëŠ” U, D, L, R ì™¸ì˜ ëª¨ë“  ë¬¸ì ì œê±°

**ë™ì‘ ì˜ˆì‹œ:**
```python
text = "I should go up. \\boxed{UUU}"
extract_boxed(text) â†’ "UUU"
re.sub(r"[^UDLR]", "", "UUU") â†’ "UUU"
```

---

## 2ï¸âƒ£ PlanningAgent.think() - ì¥ê¸° ê³„íš ì „ëµ

**ìœ„ì¹˜**: `src/realtimegym/agents/planning.py:30-64`

```python
def think(self, timeout: Optional[float] = None) -> None:
    assert timeout is not None and self.current_observation is not None
    budget = timeout

    observation = self.current_observation
    game_turn = observation["game_turn"]
    prompt_gen = self.prompts.state_to_description(
        observation["state"], mode="planning"
    )

    prompt = ""
    if self.gen_text == "":  # check whether the last generation is finished
        messages = [{"role": "user", "content": prompt_gen}]
        prompt = messages[-1]["content"]
    else:
        messages = []

    text, token_num, turn = self.planning_inference(messages, budget, game_turn)
    temp = extract_boxed(text)
    if temp != "":
        self.plan = re.sub(r"[^" + self.prompts.ALL_ACTIONS + "]", "", temp)
        if self.skip_action:
            self.plan = (
                self.plan[observation["game_turn"] - turn :]
                if len(self.plan) > observation["game_turn"] - turn
                else ""
            )

    if self.log_thinking:
        self.logs["plan"].append(self.plan)
        self.logs["model2_prompt"].append(prompt)
        self.logs["model2_response"].append(text)
    self.logs["model2_token_num"].append(token_num)
    self.action = self.plan[0] if self.plan != "" else self.prompts.DEFAULT_ACTION
    self.plan = self.plan[1:] if self.plan != "" else ""
```

### í•µì‹¬ íŠ¹ì§•

**ğŸ¯ ì—¬ëŸ¬ í„´ì— ê±¸ì¹œ ì¥ê¸° ê³„íš**
- í•œ ë²ˆ ìƒì„±í•œ ê³„íšì„ ì—¬ëŸ¬ í„´ì—ì„œ ì¬ì‚¬ìš©
- `self.plan`ì— ì•¡ì…˜ ì‹œí€€ìŠ¤ ì €ì¥ (ì˜ˆ: "UUUDDLR")
- ë§¤ í„´ë§ˆë‹¤ ì²« ê¸€ìë§Œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë‹¤ìŒ í„´ìœ¼ë¡œ

### ë‹¨ê³„ë³„ ë¶„ì„

#### Step 1: ê³„íš ìƒì„± ì§€ì† ì—¬ë¶€ í™•ì¸ (Line 41-46)
```python
prompt = ""
if self.gen_text == "":  # check whether the last generation is finished
    messages = [{"role": "user", "content": prompt_gen}]
    prompt = messages[-1]["content"]
else:
    messages = []
```
**í•µì‹¬ ê°œë…: ìŠ¤íŠ¸ë¦¬ë° ìƒì„±**
- `self.gen_text`: í˜„ì¬ ìƒì„± ì¤‘ì¸ í…ìŠ¤íŠ¸ ë²„í¼
- **ë¹„ì–´ìˆìŒ (`""`)**: ìƒˆ ê³„íš ì‹œì‘ â†’ í”„ë¡¬í”„íŠ¸ ì „ë‹¬
- **ë¹„ì–´ìˆì§€ ì•ŠìŒ**: ì´ì „ ê³„íš ê³„ì† ìƒì„± ì¤‘ â†’ ë¹ˆ ë©”ì‹œì§€

**Python ë¬¸ë²•: ì¡°ê±´ í‘œí˜„ì‹**
- `if ì¡°ê±´: ... else: ...`: ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì½”ë“œ ì‹¤í–‰

#### Step 2: Planning ì¶”ë¡  (Line 48)
```python
text, token_num, turn = self.planning_inference(messages, budget, game_turn)
```
**3ê°œ ê°’ ì–¸íŒ¨í‚¹**
- `text`: ìƒì„±ëœ ê³„íš í…ìŠ¤íŠ¸
- `token_num`: ì‚¬ìš©í•œ í† í° ìˆ˜
- `turn`: ê³„íšì´ ì‹œì‘ëœ í„´ ë²ˆí˜¸

#### Step 3: ì•¡ì…˜ ì‹œí€€ìŠ¤ ì¶”ì¶œ (Line 49-56)
```python
temp = extract_boxed(text)
if temp != "":
    self.plan = re.sub(r"[^" + self.prompts.ALL_ACTIONS + "]", "", temp)
    if self.skip_action:
        self.plan = (
            self.plan[observation["game_turn"] - turn :]
            if len(self.plan) > observation["game_turn"] - turn
            else ""
        )
```
**Python ë¬¸ë²•: ì‚¼í•­ ì—°ì‚°ì (Ternary Operator)**
```python
ê°’ = A if ì¡°ê±´ else B
```
- ì¡°ê±´ì´ `True`ë©´ `A`, `False`ë©´ `B`
- í•œ ì¤„ë¡œ if-else í‘œí˜„

**skip_action ë¡œì§:**
```python
# í„´3ì—ì„œ "UUUDDLR" ê³„íš ìƒì„±
# í˜„ì¬ í„´5ë¼ë©´:
game_turn = 5, turn = 3
skip_count = 5 - 3 = 2
self.plan = "UUUDDLR"[2:] = "UDDLR"  # ì• 2ê°œ ê±´ë„ˆë›°ê¸°
```

**Python ë¬¸ë²•: ìŠ¬ë¼ì´ì‹± (Slicing)**
```python
string[start:end]     # startë¶€í„° end-1ê¹Œì§€
string[2:]            # ì¸ë±ìŠ¤ 2ë¶€í„° ëê¹Œì§€
string[:5]            # ì²˜ìŒë¶€í„° ì¸ë±ìŠ¤ 4ê¹Œì§€
string[1:]            # ì²« ê¸€ì ì œê±°
```

#### Step 4: í˜„ì¬ ì•¡ì…˜ ì„ íƒ (Line 63-64)
```python
self.action = self.plan[0] if self.plan != "" else self.prompts.DEFAULT_ACTION
self.plan = self.plan[1:] if self.plan != "" else ""
```
**ë™ì‘:**
1. ê³„íšì˜ ì²« ê¸€ìë¥¼ í˜„ì¬ ì•¡ì…˜ìœ¼ë¡œ
2. ê³„íšì—ì„œ ì²« ê¸€ì ì œê±° (ë‹¤ìŒ í„´ì„ ìœ„í•´)

**ì˜ˆì‹œ:**
```python
self.plan = "UUUDD"
self.action = "U"       # ì²« ê¸€ì
self.plan = "UUDD"      # ë‚˜ë¨¸ì§€
```

---

## 3ï¸âƒ£ AgileThinker.think() - í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ

**ìœ„ì¹˜**: `src/realtimegym/agents/agile.py:33-69`

```python
def think(self, timeout: Optional[float] = None) -> None:
    assert self.current_observation is not None and timeout is not None
    budget = timeout
    observation = self.current_observation
    self.state_string = observation["state_string"]
    game_turn = observation["game_turn"]
    prompt_gen = self.prompts.state_to_description(
        observation["state"], mode="agile"
    )
    prompt = ""
    if self.gen_text == "":  # check whether the last generation is finished
        messages = [{"role": "user", "content": prompt_gen["planning"]}]
        prompt = messages[-1]["content"]
    else:
        messages = []
    text, token_num, turn = self.planning_inference(messages, budget, game_turn)
    self.plan = f"""**Guidance from a Previous Thinking Model:** Turn \\( t_1 = {turn} \\)\n{text}"""
    if self.log_thinking:
        self.logs["plan"].append(self.plan)
        self.logs["model2_prompt"].append(prompt)
        self.logs["model2_response"].append(text)
    self.logs["model2_token_num"].append(token_num)

    prompt = prompt_gen["reactive"]
    if self.plan is not None:
        lines = self.plan.split("\n")
        for line in lines:
            prompt += f"> {line.strip()}\n"
    messages = [{"role": "user", "content": prompt}]
    text, token_num = self.reactive_inference(messages, self.internal_budget)
    self.action = re.sub(
        r"[^" + self.prompts.ALL_ACTIONS + "]", "", extract_boxed(text)
    )
    if self.log_thinking:
        self.logs["model1_prompt"].append(prompt)
        self.logs["model1_response"].append(text)
    self.logs["model1_token_num"].append(token_num)
```

### í•µì‹¬ íŠ¹ì§•

**ğŸ¯ ë‘ ëª¨ë¸ì˜ í˜‘ì—…**
- **Phase 1**: Planning ëª¨ë¸ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°€ì´ë˜ìŠ¤ ìƒì„±
- **Phase 2**: Reactive ëª¨ë¸ì´ ê°€ì´ë˜ìŠ¤ + í˜„ì¬ ê´€ì°°ë¡œ ìµœì¢… ê²°ì •
- ì¥ê¸° ì „ëµ + ì¦‰ê° ëŒ€ì‘ì˜ ì¥ì  ê²°í•©

### ë‹¨ê³„ë³„ ë¶„ì„

#### Phase 1: Planning (Line 39-54)

```python
prompt_gen = self.prompts.state_to_description(
    observation["state"], mode="agile"
)
```
**Python ë¬¸ë²•: ë”•ì…”ë„ˆë¦¬ ë°˜í™˜**
```python
# prompt_genì€ ë”•ì…”ë„ˆë¦¬:
{
    "planning": "ì¥ê¸° ê³„íšìš© í”„ë¡¬í”„íŠ¸...",
    "reactive": "ì¦‰ê° ë°˜ì‘ìš© í”„ë¡¬í”„íŠ¸..."
}
```

```python
messages = [{"role": "user", "content": prompt_gen["planning"]}]
```
- `prompt_gen["planning"]`: ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ê°’ ì ‘ê·¼

```python
self.plan = f"""**Guidance from a Previous Thinking Model:** Turn \\( t_1 = {turn} \\)\n{text}"""
```
**Python ë¬¸ë²•: f-string (í¬ë§· ë¬¸ìì—´)**
- `f"..."`: ì¤‘ê´„í˜¸ `{}` ì•ˆì˜ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
- `\\(`: ë°±ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í”„ (LaTeX ìˆ˜ì‹ìš©)
- `\n`: ì¤„ë°”ê¿ˆ ë¬¸ì
- ì‚¼ì¤‘ ë”°ì˜´í‘œ `"""..."""`: ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´

**ì˜ˆì‹œ:**
```python
turn = 5
text = "Move up to avoid cars"
result = f"**Guidance:** Turn \\( t_1 = {turn} \\)\n{text}"
# ì¶œë ¥:
# **Guidance:** Turn \( t_1 = 5 \)
# Move up to avoid cars
```

#### Phase 2: Reactive (Line 56-69)

```python
prompt = prompt_gen["reactive"]
if self.plan is not None:
    lines = self.plan.split("\n")
    for line in lines:
        prompt += f"> {line.strip()}\n"
```
**Python ë¬¸ë²•: ë¬¸ìì—´ ë©”ì„œë“œ**
- `.split("\n")`: ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
- `.strip()`: ì•ë’¤ ê³µë°± ì œê±°
- `+=`: ë¬¸ìì—´ ì—°ê²° (concatenation)

**Python ë¬¸ë²•: for ë£¨í”„**
```python
for ë³€ìˆ˜ in ì»¬ë ‰ì…˜:
    # ê° ìš”ì†Œì— ëŒ€í•´ ë°˜ë³µ
```

**ë™ì‘ ì˜ˆì‹œ:**
```python
self.plan = "Line1\nLine2\nLine3"
lines = ["Line1", "Line2", "Line3"]
prompt = "Initial: "
# ë°˜ë³µ:
prompt += "> Line1\n"  # "Initial: > Line1\n"
prompt += "> Line2\n"  # "Initial: > Line1\n> Line2\n"
prompt += "> Line3\n"  # "Initial: > Line1\n> Line2\n> Line3\n"
```
**ê²°ê³¼**: Planning ì¶œë ¥ì„ ì¸ìš© í˜•ì‹(`>`)ìœ¼ë¡œ Reactive í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€

```python
text, token_num = self.reactive_inference(messages, self.internal_budget)
```
- `self.internal_budget`: Reactive ëª¨ë¸ ì „ìš© ì˜ˆì‚°
- `timeout - internal_budget`: Planning ëª¨ë¸ì´ ì‚¬ìš©

---

## ğŸ”„ ì„¸ ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ íë¦„ ë¹„êµ

### ReactiveAgent
```
ê´€ì°° â†’ Reactive ì¶”ë¡  (ì „ì²´ budget) â†’ ì•¡ì…˜ ì¶”ì¶œ â†’ ì¢…ë£Œ
```

### PlanningAgent
```
í„´1: ê´€ì°° â†’ Planning ì‹œì‘ â†’ ê³„íš[0] ì‚¬ìš© â†’ ê³„íš[1:] ì €ì¥
í„´2: ê´€ì°° â†’ Planning ê³„ì† â†’ ê³„íš[0] ì‚¬ìš© â†’ ê³„íš[1:] ì €ì¥
í„´3: Planning ì™„ë£Œ â†’ ê³„íš ì‹œí€€ìŠ¤ ìƒì„± ("UUUDD")
í„´4: ì €ì¥ëœ ê³„íš[0] ì‚¬ìš© ("U")
í„´5: ì €ì¥ëœ ê³„íš[0] ì‚¬ìš© ("U")
...
```

### AgileThinker
```
ê´€ì°° â†’ [Planning ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)]
     â†“
     Planning ì¶œë ¥ (ë¶€ë¶„) â†’ Reactiveì— ì „ë‹¬
     â†“
     Reactive ì¶”ë¡  (internal_budget) â†’ ìµœì¢… ì•¡ì…˜
```

---

## ğŸ“ˆ ì˜ˆì‚°(Budget) ì‚¬ìš© ë¹„êµ

### í† í° ê¸°ë°˜ (time_unit="token")

| ì—ì´ì „íŠ¸ | ì´ ì˜ˆì‚° 8192 í† í° | Planning | Reactive |
|---------|----------------|----------|----------|
| ReactiveAgent | 8192 | âŒ 0 | âœ… 8192 |
| PlanningAgent | 8192 | âœ… 8192 | âŒ 0 |
| AgileThinker | 8192 | âœ… 4096 | âœ… 4096 |

### ì‹œê°„ ê¸°ë°˜ (time_unit="seconds")

| ì—ì´ì „íŠ¸ | ì´ ì˜ˆì‚° 10ì´ˆ | Planning | Reactive |
|---------|------------|----------|----------|
| ReactiveAgent | 10ì´ˆ | âŒ 0ì´ˆ | âœ… 10ì´ˆ |
| PlanningAgent | 10ì´ˆ | âœ… 10ì´ˆ | âŒ 0ì´ˆ |
| AgileThinker | 10ì´ˆ | âœ… 6ì´ˆ | âœ… 4ì´ˆ |

---

## ğŸ§  í•µì‹¬ Python ë¬¸ë²• ì •ë¦¬

### 1. **íŠœí”Œ ì–¸íŒ¨í‚¹ (Tuple Unpacking)**
```python
text, token_num = function()  # 2ê°œ
text, token_num, turn = function()  # 3ê°œ
```

### 2. **ì¡°ê±´ í‘œí˜„ì‹ (Ternary Operator)**
```python
value = A if condition else B
```

### 3. **ì •ê·œí‘œí˜„ì‹ (Regular Expression)**
```python
re.sub(pattern, replacement, string)  # ì¹˜í™˜
r"..."  # raw string (ì´ìŠ¤ì¼€ì´í”„ ë¶ˆí•„ìš”)
[^ABC]  # ABCê°€ ì•„ë‹Œ ë¬¸ì
```

### 4. **ìŠ¬ë¼ì´ì‹± (Slicing)**
```python
string[0]     # ì²« ê¸€ì
string[1:]    # ì²« ê¸€ì ì œì™¸í•œ ë‚˜ë¨¸ì§€
string[n:]    # në²ˆì§¸ ì¸ë±ìŠ¤ë¶€í„°
```

### 5. **f-string (í¬ë§· ë¬¸ìì—´)**
```python
f"Value: {variable}"
f"Calc: {x + y}"
```

### 6. **ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼**
```python
dict = {"key1": "value1", "key2": "value2"}
dict["key1"]  # "value1"
```

### 7. **ë¬¸ìì—´ ë©”ì„œë“œ**
```python
string.split("\n")   # ë¶„ë¦¬ â†’ ë¦¬ìŠ¤íŠ¸
string.strip()       # ê³µë°± ì œê±°
string += "text"     # ë¬¸ìì—´ ì¶”ê°€
```

---

## ğŸ’¡ ì „ëµì  ì°¨ì´ì  ìš”ì•½

| ì¸¡ë©´ | ReactiveAgent | PlanningAgent | AgileThinker |
|------|--------------|---------------|--------------|
| **ì í•©í•œ ìƒí™©** | ë¹ ë¥¸ ë°˜ì‘ í•„ìš” | ë³µì¡í•œ ì¥ê¸° ì „ëµ | ê· í˜• ì¡íŒ ì ‘ê·¼ |
| **ê°•ì ** | ë‹¨ìˆœ, ë¹ ë¦„ | ì¼ê´€ëœ ì¥ê¸° ê³„íš | ìœ ì—°ì„±, ì ì‘ì„± |
| **ì•½ì ** | ê·¼ì‹œì•ˆì  | ë³€í™” ëŒ€ì‘ ëŠë¦¼ | ë³µì¡ì„±, ë¹„ìš© ë†’ìŒ |
| **ì½”ë“œ ë³µì¡ë„** | â­ ë‚®ìŒ | â­â­ ì¤‘ê°„ | â­â­â­ ë†’ìŒ |
| **ê³„ì‚° ë¹„ìš©** | ğŸ’° ë‚®ìŒ | ğŸ’°ğŸ’° ì¤‘ê°„ | ğŸ’°ğŸ’°ğŸ’° ë†’ìŒ |

---

## ğŸ“ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

### ReactiveAgent ì‹¤í–‰
```bash
agile_eval --time_unit token \
    --time_pressure 8192 \
    --game freeway \
    --cognitive_load E \
    --mode reactive \
    --reactive-model-config configs/example-deepseek-v3.2-reactive.yaml \
    --seed_num 1 --repeat_times 1
```

### PlanningAgent ì‹¤í–‰
```bash
agile_eval --time_unit token \
    --time_pressure 8192 \
    --game freeway \
    --cognitive_load E \
    --mode planning \
    --planning-model-config configs/example-deepseek-v3.2-planning.yaml \
    --seed_num 1 --repeat_times 1
```

### AgileThinker ì‹¤í–‰
```bash
agile_eval --time_unit token \
    --time_pressure 8192 \
    --internal_budget 4096 \
    --game freeway \
    --cognitive_load E \
    --mode agile \
    --reactive-model-config configs/example-deepseek-v3.2-reactive.yaml \
    --planning-model-config configs/example-deepseek-v3.2-planning.yaml \
    --seed_num 1 --repeat_times 1
```
